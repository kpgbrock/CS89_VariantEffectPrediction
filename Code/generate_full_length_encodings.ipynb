{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6lORsxsf2Lvc","outputId":"734789b7-a05e-496a-cfb5-99439ecd00ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==1.15.5\n","  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n","\u001b[K     |████████████████████████████████| 110.5 MB 1.2 kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 32.2 MB/s \n","\u001b[?25hCollecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 3.9 MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.14.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n","Collecting h5py<=2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 26.6 MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[K     |████████████████████████████████| 503 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Collecting numpy<1.19.0,>=1.16.0\n","  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.47.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.4.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.1.1)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=2ef13b9ae1d83ba057cd0e5a94a91a37aad48890a42d496045a4505109c87869\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: numpy, h5py, tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n","jaxlib 0.3.14+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.14 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"}],"source":["# We're using the UniRep paper by Alley et al 2019, that has trained an encoding\n","# space for proteins (taking variable-length sequences into a vector of 64 \n","# encodings). To make this work, we need a specific older version of TensorFlow.\n","!pip install tensorflow==1.15.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGV67_fYU5RR"},"outputs":[],"source":["# We're cloning the github repo that ahs the code we need to run this - note\n","# that the first time you run it, it will do the cloning; subsequent times will\n","# give a 'directory already made' error.\n","!git clone https://github.com/churchlab/UniRep.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMVn948FZQpx"},"outputs":[],"source":["# Go into our cloned github repo with code from Alley et al 2019.\n","cd UniRep"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23121,"status":"ok","timestamp":1659208219637,"user":{"displayName":"Kelly Brock","userId":"15095971254174684161"},"user_tz":240},"id":"qJ3GDmFrUwT4","outputId":"30decb8d-d548-4ad1-b6da-298976dcae9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","WARNING:tensorflow:From /content/UniRep/unirep.py:43: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n","\n","1.15.5\n"]}],"source":["# Load in our dependencies\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import copy\n","import random as python_random\n","import tensorflow as tf\n","from google.colab import files\n","\n","# Note: this must be run in a kernel with TF version 1.15 - that's what the \n","# above cells are doing\n","\n","# set seeds\n","np.random.seed(768)\n","python_random.seed(869)\n","tf.random.set_random_seed(1234)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from unirep import babbler64 as babbler\n","\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cl0W74iE455D"},"outputs":[],"source":["# Load in premade weights from UniRep encoding paper (Alley et al 2019)\n","weights_path = \"/content/drive/MyDrive/DeepLearning_Summer2022/Final_Project/Data/UniRep_Weights/64_weights/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21305,"status":"ok","timestamp":1659208249957,"user":{"displayName":"Kelly Brock","userId":"15095971254174684161"},"user_tz":240},"id":"Gs7Et9AgSq0S","outputId":"7bfbe096-6d89-47e6-fd7f-f30922ad966c"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /content/UniRep/unirep.py:710: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/UniRep/unirep.py:739: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/UniRep/unirep.py:748: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/UniRep/unirep.py:205: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n","Instructions for updating:\n","dim is deprecated, use axis instead\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/UniRep/unirep.py:29: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/distributions/categorical.py:242: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/distributions/categorical.py:278: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","WARNING:tensorflow:From /content/UniRep/unirep.py:776: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n"]}],"source":["# Let's test to make sure we can run their weights + model\n","batch_size = 12\n","b = babbler(batch_size=batch_size, model_path=weights_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223,"status":"ok","timestamp":1659208250174,"user":{"displayName":"Kelly Brock","userId":"15095971254174684161"},"user_tz":240},"id":"EckrBO0IVlwE","outputId":"e0c7412c-dd43-4290-d8fb-a3dcb2a02f52"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /content/UniRep/unirep.py:35: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /content/UniRep/unirep.py:36: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /content/UniRep/unirep.py:39: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"]}],"source":["# Testing an individual sequence\n","test_sequence = \"MANLGCWMLVLFVATWSDLGLCKKRPKPGGWNTGGSRYPGQGSPGGNRYPPQGGGGWGQPHGGGWGQPHGGGWGQPHGGGWGQPHGGGWGQGGGTHSQWNKPSKPKTNMKHMAGAAAAGAVVGGLGGYMLGSAMSRPIIHFGSDYEDRYYRENMHRYPNQVYYRPMDEYSNQNNFVHDCVNITIKQHTVTTTTKGENFTETDVKMMERVVEQMCITQYERESQAYYQRGSSMVLFSSPPVILLISFLIFLIVG\"\n","avg_hidden, final_hidden, final_cell = b.get_rep(test_sequence)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1659208299634,"user":{"displayName":"Kelly Brock","userId":"15095971254174684161"},"user_tz":240},"id":"xyCEV33EWJRp","outputId":"16803fba-607e-4940-c7ea-988476f7a5cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["(64,)\n","(64,)\n","(64,)\n"]}],"source":["print(avg_hidden.shape)\n","print(final_hidden.shape)\n","print(final_cell.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1659208303659,"user":{"displayName":"Kelly Brock","userId":"15095971254174684161"},"user_tz":240},"id":"TSvyYTmhWLcI","outputId":"5eb6abb7-095b-4ca7-ad9f-b6284422c8df"},"outputs":[{"data":{"text/plain":["array([-0.03392499,  0.4642311 ,  0.5833186 , -2.6741865 ,  0.12040318,\n","       -0.98775893,  1.378801  ,  1.0598173 ,  0.96727955,  0.6003299 ,\n","        1.251148  ,  1.9921563 ,  0.09310557,  1.6740963 ,  0.15809879,\n","       -2.1900048 , -1.4988172 ,  0.05234914,  0.60021186, -3.717322  ,\n","       -0.34242752,  3.0133345 , -2.5500371 , -0.5607802 ,  4.998315  ,\n","       -0.12100416,  0.13841838,  0.218849  ,  4.139292  , -3.3598323 ,\n","        1.5299058 ,  0.5911101 ,  4.848772  , -0.4276914 ,  0.868774  ,\n","        0.19071291, -0.6580446 ,  0.15731928,  0.57896996, -0.5961143 ,\n","        0.08143958,  0.47155276,  0.15586367,  2.195258  , -0.04211713,\n","        2.1800363 , -5.5114126 , -9.715301  ,  1.9706156 ,  1.7465513 ,\n","        0.42815694,  0.32075572, -0.21909057, -0.21982038,  0.31077018,\n","        0.27156875,  0.06501038,  0.07555409, -0.28645086, 18.441698  ,\n","       -0.16832477, -0.05181318,  6.2898474 , -0.32685822], dtype=float32)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["final_cell"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gf49TJOxZnOV","outputId":"207a685d-61ab-406b-fd33-43d25c277cb9","executionInfo":{"status":"ok","timestamp":1659250676300,"user_tz":240,"elapsed":16551232,"user":{"displayName":"Kelly Brock","userId":"15095971254174684161"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 20387/20387 [5:01:02<00:00,  1.13it/s]\n"]}],"source":["# Here's the big run. We're going to load in my list of all canonical proteins\n","# and their sequences, and run them individually through the encodings module\n","# to get 64-depth encodings for each sequence. This takes a while to run.\n","df = pd.read_csv('/content/drive/MyDrive/DeepLearning_Summer2022/Final_Project/Data/precursor_files/uniprot_canonical_human_proteins.tsv',sep='\\t')\n","N = len(df)\n","\n","from tqdm import tqdm\n","\n","# Store output in a dictionary, with Uniprot identifier as the key and the \n","# array of 64 encodings as the value\n","protein_encodings = {}\n","for i in tqdm(range(N)):\n","  _, _, final_cell = b.get_rep(df.iloc[i]['Sequence'])\n","  uniprot = df.iloc[i]['Entry']\n","  protein_encodings[uniprot] = final_cell\n","  tf.reset_default_graph() "]},{"cell_type":"code","execution_count":13,"metadata":{"id":"J02i2qemZ-PE","executionInfo":{"status":"ok","timestamp":1659250676301,"user_tz":240,"elapsed":2,"user":{"displayName":"Kelly Brock","userId":"15095971254174684161"}}},"outputs":[],"source":["# Finally, let's dump this dictionary in a pickle file so that we can access it\n","# later\n","import pickle\n","encodings_file = '/content/drive/MyDrive/DeepLearning_Summer2022/Final_Project/Data/protein_full_length_encodings.pickle'\n","with open(encodings_file,'wb') as f:\n","  pickle.dump(protein_encodings,f,protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skOwnnq-hbwC"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"generate_full_length_encodings.ipynb","provenance":[],"authorship_tag":"ABX9TyNiwYZfK/fDY8Spwl/ayPJ8"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}